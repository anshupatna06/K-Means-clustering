# K-Means-clustering
"ML models implemented from scratch using NumPy and Pandas only"


ðŸ“Œ K-Means Clustering from Scratch

This project implements K-Means Clustering from scratch using NumPy & Matplotlib, along with visualizations and a comparison with sklearn.


---

ðŸš€ Features

Step-by-step scratch implementation of K-Means

Visualization of clusters and centroids

Elbow Method for selecting the optimal number of clusters

Comparison with Sklearn KMeans for validation



---

ðŸ“Š Algorithm Workflow

1. Initialize k centroids randomly.


2. Assign each point to the nearest centroid (label).


3. Update centroids as the mean of assigned points.


4. Repeat until centroids stop moving (convergence).




---

ðŸ“· Visualizations

Raw dataset

Iterative updates of clusters & centroids

Final clustered result

Elbow Curve (SSE vs k)



---

ðŸ“ˆ Example Output

Scratch K-Means
Scratch KMeans SSE: 1755.0618453393215


Elbow Method



Sklearn Comparison
Sklearn KMeans SSE: 203.89074684058343



---

ðŸ›  Tech Stack

Python 3

NumPy

Matplotlib

Scikit-learn (only for comparison)



---

ðŸ“‚ Project Structure

kmeans_scratch/
â”‚â”€â”€ kmeans_scratch.py      # Core scratch implementation
â”‚â”€â”€ elbow_method.py        # Elbow method implementation
â”‚â”€â”€ comparison.py          # Comparison with sklearn
â”‚â”€â”€ README.md              # Documentation
â”‚â”€â”€ images/                # Plots & screenshots


---

âœ… Results

Scratch implementation gives centroids & SSE very close to sklearnâ€™s implementation.

Elbow method correctly identifies the optimal cluster count.



---

âœ¨ Inspired by learning algorithms from scratch for deeper understanding.
